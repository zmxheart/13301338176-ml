<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Blog blog("Baptiste Wicht"); (Posts about Intel)</title><link>http://baptiste-wicht.com/</link><description></description><atom:link type="application/rss+xml" rel="self" href="http://baptiste-wicht.com/categories/intel.xml"></atom:link><language>en</language><lastBuildDate>Tue, 17 Oct 2017 18:58:43 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Speed up TensorFlow inference by compiling it from source</title><link>http://baptiste-wicht.com/posts/2017/05/speed-up-tensorflow-inference-compiling-from-source.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;The most simple way to install TensorFlow is to work in a virtual Python
environment and simply to use either the TensorFlow official packages in pip or
use one of the official wheels for distributions.  There is one big problem with
that technique and it's the fact that the binaries are precompiled so that they
fit as many hardware configuration as possible. This is normal from Google since
generating precompiled binaries for all the possible combinations of processor
capabilities would be a nightmare. This is not a problem for GPU
since the CUDA Libraries will take care of the difference from one graphics card
to another. But it is a problem with CPU performance. Indeed, different
processors have different capabilities. For instance, the vectorization
capabilities are different from processor to processor (SSE, AVX, AVX2,
AVX-512F, FMA, ...). All those options can make a significant difference in the
performance of the programs. Although most of the machine learning training
occurs on GPU most of the time, the inference is mostly done on the CPU.
Therefore, it probably remains important to be as fast as possible on CPU.&lt;/p&gt;
&lt;p&gt;So if you care about performance on CPU, you should install TensorFlow from
sources directly yourself. This will allow compilation of the TensorFlow sources
with -march=native which will enable all the hardware capabilities of machine on
which you are compiling the library.&lt;/p&gt;
&lt;p&gt;Depending on your problem, this may give you some nice speedup. In my case, on
a very small Recurrent Neural Network, it made inference about 20% faster.  On
a larger problem and depending on your processor, you may gain much more than
that. If you are training on CPU, this may make a very large difference in total
time.&lt;/p&gt;
&lt;p&gt;Installing TensorFlow is sometimes a bit cumbersome. You'll likely have to
compile Bazel from sources as well and depending on your processor, it may take
a long time to finish. Nevertheless, I have successfully compiled TensorFlow
from sources on several machines now without too many problems. Just pay close
attention to the options you are setting while configuring TensorFlow, for
instance CUDA configuration if you want GPU support.&lt;/p&gt;
&lt;p&gt;I hope this little trick will help you gain some time :)&lt;/p&gt;
&lt;p&gt;Here is the &lt;a class="reference external" href="https://www.tensorflow.org/install/install_sources"&gt;link to compile TensorFlow from source&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>CPU</category><category>GPU</category><category>Intel</category><category>Machine Learning</category><category>Performance</category><category>tensorflow</category><guid>http://baptiste-wicht.com/posts/2017/05/speed-up-tensorflow-inference-compiling-from-source.html</guid><pubDate>Wed, 10 May 2017 12:18:33 GMT</pubDate></item><item><title>Publication: CPU Performance Optimizations for RBM and CRBM</title><link>http://baptiste-wicht.com/posts/2017/02/publication-cpu-performance-optimizations-rbm-crbm.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;Recently, we have published a paper about performance optimizations that may
interest you.&lt;/p&gt;
&lt;p&gt;The paper is &lt;a class="reference external" href="https://www.researchgate.net/publication/307908790_On_CPU_Performance_Optimization_of_Restricted_Boltzmann_Machine_and_Convolutional_RBM"&gt;On CPU Performance Optimizations for Restricted Boltzmann Machine and Convolutional RBM&lt;/a&gt;, published in the Proceedings of the Artificial Neural Networks and Pattern Recognition workshop (ANNPR-2016). I've presented this paper in Germany, at Ulm.&lt;/p&gt;
&lt;p&gt;Although most of the performance research going on is focused on GPU, there are
still of research laboratories that are only equipped with CPU and it remains
important to be as fast as possible on CPU. Moreover, this is something
I really like.&lt;/p&gt;
&lt;p&gt;For this publication, I have tried to make my Restricted Boltzmann Machine (RBM)
and Convolutional RBM (CRBM) implementations in my DLL library as fast as
possible.&lt;/p&gt;
&lt;p&gt;The first part of the article is about Restricted Boltzmann Machine (RBM) which
are a form of dense Artificial Neural Network (ANN). Their training is very
similar to that of the ANN with Gradient Descent. Four different network
configurations are being tested.&lt;/p&gt;
&lt;p&gt;First, mini-batch training is shown to be much faster than online training, even
when online training is performed in parallel. Once mini-batch training is used,
BLAS operations are used in order to get as much performance as possible on the
different operations, mainly the Matrix Matrix Multiplication with the use of
the GEMM operation from the Intel Math Kernel Library (MKL). Moreover, the
parallel version of the MKL is also used to get even more performance. When all
these optimizations are performed, speedups of 11 to 30 are obtained compared to
the online training, depending on the network configurations. This final version
is able  to perform one epoch of Contrastive Divergence in 4 to 15 seconds
depending on the network, for 60000 images.&lt;/p&gt;
&lt;p&gt;The second part of the article is about Convolutional Restricted Boltzmann
Machine (CRBM). This is almost the equivalent of a Convolutional Neural Network
(CNN). Again four different networks are evaluated.&lt;/p&gt;
&lt;p&gt;The main problem with CRBM is that there are no standard implementations of the
convolution operation that is really fast. Therefore, it is not possible to
simply use a BLAS library to make the computation as fast as possible. The first
optimization that was tried is to vectorize the convolutions. With this, the
speedups have been between 1.1 and 1.9 times faster. I'm not really satisfied
with these results since in fact per convolution the speedups are much better.
Moreover, I have since been able to obtain better speedups but the deadline was
too short to include them in this paper. I'll try to talk about these
improvements in more details on this blog. What is more interesting to to
parallellize the different convolutions since they are mostly independent. This
can bring a speedup of the amount of cores available on the machine. Since
convolutions are extremely memory hungry, virtual cores with Hyper Threading
generally does not help. An interesting optimization is to use a Matrix
Multiplication to compute several valid convolutions at once.  This can give an
additional speedup between 1.6 and 2.2 compared to the vectorized version. While
it is possible to use the FFT to reduce the full convolution as well, in our
experiment the images were not big enough for this to be interesting. The final
speedups are about 10 times faster with these optimizations.&lt;/p&gt;
&lt;p&gt;We have obtained pretty good and I'm happy we have been published. However, I'm
not very satisfied with these results since I've been able to get even faster
since this and when compared with other frameworks, DLL is actually quite
competitive. I'll try to publish something new in the future.&lt;/p&gt;
&lt;p&gt;If you want more information, you can have a look at the paper. If you want to
look at the code, you can have a look at my projects:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/wichtounet/etl"&gt;Expression Templates Library (ETL)&lt;/a&gt;: For
the Matrix Multiplication and Convolutions&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;Deep Learning Library (DLL)&lt;/a&gt;: For the RBM
and CRBM implementations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Don't hesitate to ask any questions if you want more information :)&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>CPU</category><category>crbm</category><category>dbn</category><category>deep learning</category><category>dll</category><category>etl</category><category>Intel</category><category>Performances</category><category>publications</category><category>rbm</category><category>thesis</category><guid>http://baptiste-wicht.com/posts/2017/02/publication-cpu-performance-optimizations-rbm-crbm.html</guid><pubDate>Tue, 07 Feb 2017 16:33:33 GMT</pubDate></item><item><title>Memory Manager in 64bits Intel Assembly on Linux</title><link>http://baptiste-wicht.com/posts/2012/08/memory-manager-intel-assembly-64-linux.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;For &lt;a title="EDDI Compiler 1.1.1 – Dynamic Memory Allocation and Constructors/Destructors" href="http://www.baptiste-wicht.com/2012/07/eddi-compiler-1-1-1-dynamic-memory-allocation-constructors-destructors/"&gt;the last version of the EDDI Compiler&lt;/a&gt;, it has been necessary to extend the dynamic memory allocator, to support free memory. In this post, we will see how to write a simple Memory Manager in Intel Assembly for Linux.&lt;/p&gt;
&lt;p&gt;In the past, we've seen &lt;a title="Dynamic memory allocation in Intel Assembly on Linux" href="http://www.baptiste-wicht.com/2011/11/dynamic-memory-allocation-intel-assembly-linux/"&gt;how to write a basic memory allocator&lt;/a&gt;, this time, we will write a more complete version.&lt;/p&gt;
&lt;p&gt;The implementation is made in 64bits Intel Assembly.&lt;/p&gt;
&lt;h4&gt;Memory Manager specification&lt;/h4&gt;

&lt;p&gt;The memory will be allocated by blocks. Each block will contain a header with two information:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;A boolean flag indicating if the block is free or not&lt;/li&gt;
    &lt;li&gt;The size of the block (including the header)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each time some memory is asked, the blocks are tested one by one until an available one is found. If no available block is found, a new block is allocated after the last one and this block is returned.&lt;/p&gt;
&lt;p&gt;The memory manager consists of three functions:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;memory_init: Init the memory manager&lt;/li&gt;
    &lt;li&gt;memory_alloc: Allocate the given number of bytes of memory&lt;/li&gt;
    &lt;li&gt;memory_free: Release the given block&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The parameter is passed in the &lt;strong&gt;r14&lt;/strong&gt; register. The return value is returned in the &lt;strong&gt;rax&lt;/strong&gt; register.&lt;/p&gt;
&lt;h4&gt;Global State&lt;/h4&gt;

&lt;p&gt;This implementation needs two global variables. One for the start address of memory and the other one for the last:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;section&lt;/span&gt; &lt;span class="nv"&gt;.data&lt;/span&gt;
&lt;span class="nf"&gt;mem_last&lt;/span&gt; &lt;span class="nv"&gt;dq&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="nf"&gt;mem_start&lt;/span&gt; &lt;span class="nv"&gt;dq&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/pre&gt;


&lt;h4&gt;Init memory Manager&lt;/h4&gt;

&lt;p&gt;The init function is very simple to implement:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;init:&lt;/span&gt;
&lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nb"&gt;rbp&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nb"&gt;rbp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;rsp&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nb"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;
&lt;span class="nf"&gt;xor&lt;/span&gt; &lt;span class="nb"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;rdi&lt;/span&gt;
&lt;span class="nf"&gt;syscall&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;mem_start&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;rax&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;mem_last&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;rax&lt;/span&gt;
&lt;span class="nf"&gt;leave&lt;/span&gt;
&lt;span class="nf"&gt;ret&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;We just have to call sys_brk in order to get the location of &lt;em&gt;program break&lt;/em&gt;. Then, the start and the last addresses are the same.&lt;/p&gt;
&lt;h4&gt;Free memory&lt;/h4&gt;

&lt;p&gt;The free function is the simplest one:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;free:&lt;/span&gt;
&lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nb"&gt;rbp&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nb"&gt;rbp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;rsp&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="kt"&gt;qword&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r14&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="nf"&gt;leave&lt;/span&gt;
&lt;span class="nf"&gt;ret&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The address to free is passed in the &lt;strong&gt;r14&lt;/strong&gt; register. We have to go back 16 bytes (size of the control block) to go to the start of the block. The availability flag is set to 1 (the block is free).&lt;/p&gt;
&lt;h4&gt;The alloc function&lt;/h4&gt;

&lt;p&gt;The alloc function is the most complex:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;alloc:&lt;/span&gt;
&lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nb"&gt;rbp&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nb"&gt;rbp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;rsp&lt;/span&gt;
&lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nb"&gt;rdi&lt;/span&gt;
&lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nv"&gt;r10&lt;/span&gt;
&lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nv"&gt;r11&lt;/span&gt;
&lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nv"&gt;r12&lt;/span&gt;
&lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nv"&gt;r13&lt;/span&gt;
&lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;
&lt;span class="nf"&gt;add&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;mem_start&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nv"&gt;r13&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;mem_last&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nl"&gt;.start:&lt;/span&gt;
&lt;span class="nf"&gt;cmp&lt;/span&gt; &lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;r13&lt;/span&gt;
&lt;span class="nf"&gt;je&lt;/span&gt; &lt;span class="nv"&gt;.alloc&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nv"&gt;r10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nv"&gt;r11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nf"&gt;cmp&lt;/span&gt; &lt;span class="nv"&gt;r10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="nf"&gt;jne&lt;/span&gt; &lt;span class="nv"&gt;.move&lt;/span&gt;
&lt;span class="nf"&gt;cmp&lt;/span&gt; &lt;span class="nv"&gt;r11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;
&lt;span class="nf"&gt;jl&lt;/span&gt; &lt;span class="nv"&gt;.move&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="kt"&gt;qword&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="nf"&gt;lea&lt;/span&gt; &lt;span class="nb"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;r13&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;r12&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;r11&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;r10&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nb"&gt;rdi&lt;/span&gt;
&lt;span class="nf"&gt;leave&lt;/span&gt;
&lt;span class="nf"&gt;ret&lt;/span&gt;

&lt;span class="nl"&gt;.move:&lt;/span&gt;
&lt;span class="nf"&gt;add&lt;/span&gt; &lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;r11&lt;/span&gt;
&lt;span class="nf"&gt;jmp&lt;/span&gt; &lt;span class="nv"&gt;.start&lt;/span&gt;

&lt;span class="nl"&gt;.alloc:&lt;/span&gt;
&lt;span class="nf"&gt;lea&lt;/span&gt; &lt;span class="nb"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nb"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;
&lt;span class="nf"&gt;syscall&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;mem_last&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;rdi&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="kt"&gt;qword&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="kt"&gt;qword&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;
&lt;span class="nf"&gt;lea&lt;/span&gt; &lt;span class="nb"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;r13&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;r12&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;r11&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;r10&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nb"&gt;rdi&lt;/span&gt;
&lt;span class="nf"&gt;leave&lt;/span&gt;
&lt;span class="nf"&gt;ret&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;As the function is a bit complex, I will detail it in part:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;add&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;mem_start&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nv"&gt;r13&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;mem_last&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nl"&gt;.start:&lt;/span&gt;
&lt;span class="nf"&gt;cmp&lt;/span&gt; &lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;r13&lt;/span&gt;
&lt;span class="nf"&gt;je&lt;/span&gt; &lt;span class="nv"&gt;.alloc&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nv"&gt;r10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nv"&gt;r11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nf"&gt;cmp&lt;/span&gt; &lt;span class="nv"&gt;r10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="nf"&gt;jne&lt;/span&gt; &lt;span class="nv"&gt;.move&lt;/span&gt;
&lt;span class="nf"&gt;cmp&lt;/span&gt; &lt;span class="nv"&gt;r11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;
&lt;span class="nf"&gt;jl&lt;/span&gt; &lt;span class="nv"&gt;.move&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="kt"&gt;qword&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="nf"&gt;lea&lt;/span&gt; &lt;span class="nb"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The necessary number of bytes is passed in the &lt;strong&gt;r14&lt;/strong&gt; register. We add 16 bytes (size of the control group) to the size as we also need some place for the header. Then, we load the start and last addresses. If both addresses are equal, we need to allocate more memory (detailed later). Then, we check the size and the availability of the current block. If the size is enough to fit the needs and the block is available, we set it to unavailable. We return the address past the control block (16 bytes).&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;.move:&lt;/span&gt;
&lt;span class="nf"&gt;add&lt;/span&gt; &lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;r11&lt;/span&gt;
&lt;span class="nf"&gt;jmp&lt;/span&gt; &lt;span class="nv"&gt;.start&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;To move to the next block, we just have to add the size of the current block to the current block address.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;.alloc:&lt;/span&gt;
&lt;span class="nf"&gt;lea&lt;/span&gt; &lt;span class="nb"&gt;rdi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nb"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;
&lt;span class="nf"&gt;syscall&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;V_mem_last&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;rdi&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="kt"&gt;qword&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="kt"&gt;qword&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;
&lt;span class="nf"&gt;lea&lt;/span&gt; &lt;span class="nb"&gt;rax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;To allocate memory, we compute the new &lt;em&gt;program break&lt;/em&gt; and call &lt;em&gt;sys_brk&lt;/em&gt; again to set the new &lt;em&gt;program break&lt;/em&gt;. The block is then set to not available and the size is set. We return the address past the control block (16 bytes).&lt;/p&gt;
&lt;p&gt;The rest of the program is just here to save and restore the registers and compute the stack frames.&lt;/p&gt;
&lt;h4&gt;Wrap-Up&lt;/h4&gt;

&lt;p&gt;In this article, we saw how to implement a very simple memory manager in 64bits Intel Assembly on Linux. This memory manager is very simple, but has several drawbacks:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;The overhead for small blocks is important. For example, allocating an 8 bytes integer needs a 24 bytes block, thrice the size of the int.&lt;/li&gt;
    &lt;li&gt;In the worst-case scenario, all of the process memory need to be walked across to find a new free block&lt;/li&gt;
    &lt;li&gt;The functions are not thread-safe&lt;/li&gt;
    &lt;li&gt;This algorithm can lead to a lot of memory fragmentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the future I will try to make a more powerful version of this memory manager.&lt;/p&gt;
&lt;h4&gt;Download&lt;/h4&gt;

&lt;p&gt;All the functions are available online on the Github Repository:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;a href="https://github.com/wichtounet/eddic/blob/develop/functions/x86_64_alloc.s"&gt;alloc&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href="https://github.com/wichtounet/eddic/blob/develop/functions/x86_64_free.s"&gt;free&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href="https://github.com/wichtounet/eddic/blob/develop/functions/x86_64_init.s"&gt;init&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;They are also available in 32bits Intel Assembly:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;a href="https://github.com/wichtounet/eddic/blob/develop/functions/x86_32_alloc.s"&gt;alloc&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href="https://github.com/wichtounet/eddic/blob/develop/functions/x86_32_free.s"&gt;free&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href="https://github.com/wichtounet/eddic/blob/develop/functions/x86_32_init.s"&gt;init&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>Assembly</category><category>Intel</category><category>Linux</category><guid>http://baptiste-wicht.com/posts/2012/08/memory-manager-intel-assembly-64-linux.html</guid><pubDate>Thu, 02 Aug 2012 06:05:30 GMT</pubDate></item><item><title>Compiler Architecture refinements for eddic</title><link>http://baptiste-wicht.com/posts/2012/05/compiler-architecture-refinements-eddic.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;The next version of eddic will see an &lt;strong&gt;improved compiler architecture&lt;/strong&gt;. There are two new main changes in this version:&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;A better separation between the front end and the back end&lt;/li&gt;
    &lt;li&gt;A new intermediate representation to improve and ease code generation&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;Front end and Back End&lt;/h4&gt;

&lt;p&gt;First, the front and back ends have been clearly separated. The general compiler architecture is currently something like that:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.baptiste-wicht.com/2012/05/compiler-architecture-refinements-eddic/general-architecture/" rel="attachment wp-att-1973"&gt;&lt;img class="aligncenter size-full wp-image-1973" title="EDDI Compiler General Architecture" src="http://baptiste-wicht.com/wp-content/uploads/2012/05/general-architecture.svg" alt="EDDI Compiler General Architecture"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first part didn't change, but the Compiler was part was clearly separated between front and back ends:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.baptiste-wicht.com/2012/05/compiler-architecture-refinements-eddic/compiler-architecture/" rel="attachment wp-att-1976"&gt;&lt;img class="aligncenter size-full wp-image-1976" title="EDDI Compiler Architecture" src="http://baptiste-wicht.com/wp-content/uploads/2012/05/compiler-architecture.svg" alt="EDDI Compiler Architecture"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The backend has no information about the source language. It only sees the intermediate representation provided by the front-end, named: Medium-Level Three Address Code (MTAC).&lt;/p&gt;
&lt;p&gt;There are several advantages to this model. The main one is that it is easy to add support for a new programming language to the compiler. Only the front end needs to be changed. The same can be achieved if a new output is necessary, for example output ARM assembly instead of Intel assembly.&lt;/p&gt;
&lt;h4&gt;New intermediate representation&lt;/h4&gt;

&lt;p&gt;In the previous versions of the compiler, the code generators were fairly complex. Indeed, they had to transform the MTAC intermediate representation directly into assembly. This process involves several things:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;instruction selection&lt;/li&gt;
    &lt;li&gt;register allocation&lt;/li&gt;
    &lt;li&gt;low-level optimization (replace a  mov rax, 0 with xor rax, rax for example)&lt;/li&gt;
    &lt;li&gt;handle basic blocks management&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this version, I decided to change it to a better architecture. This architecture uses a new intermediate representation: Low-Level Three Address Code (LTAC). As its name states, it is a low-level representation, close to assembly. In this  representation there are addresses, registers and abstracted instructions. This representation is platform independent (the differences between 32 and 64 bits are moved to the code generators). There are no more basic blocks here, only functions containing statements.&lt;/p&gt;
&lt;p&gt;The next figure presents the structure of the backend:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.baptiste-wicht.com/2012/05/compiler-architecture-refinements-eddic/backend-architecture/" rel="attachment wp-att-1977"&gt;&lt;img class="aligncenter size-full wp-image-1977" title="EDDI Compiler Backend architecture" src="http://baptiste-wicht.com/wp-content/uploads/2012/05/backend-architecture.svg" alt="EDDI Compiler Backend architecture"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The compiler is responsible for transforming the MTAC Representation in LTAC Representation. It does not do any low-level optimization. The instruction selection is easier as it is platform independent. The peephole optimizer is responsible for the low-levels optimizations. In the 1.0 release, there would be only few things done at this level. In the future, I will try to invest some time to complete it to generate better assembly code. The optimizations are far simpler than the one done in the MTAC optimization engine. Indeed, a peephole optimizer is generally working only in a small window of instructions, like three or four instructions at a time. And finally, the code generators performs the instruction selection process and address resolving. It also has to translate symbolic registers into physical ones.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;I hope that these refinements in the compiler architecture will allow the compiler to produce better code.&lt;/p&gt;
&lt;p&gt;The 1.0 version of the compiler will include another new features:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Basic support for custom structures&lt;/li&gt;
    &lt;li&gt;Global optimizations&lt;/li&gt;
    &lt;li&gt;Some bug fixes found with the new set of unit tests&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As always, feel free to comment on the new architecture, the compiler itself, the project or whatever&lt;/p&gt;&lt;/div&gt;</description><category>Assembly</category><category>Compilers</category><category>EDDI</category><category>Intel</category><category>Linux</category><guid>http://baptiste-wicht.com/posts/2012/05/compiler-architecture-refinements-eddic.html</guid><pubDate>Mon, 07 May 2012 07:34:30 GMT</pubDate></item><item><title>EDDIC 0.9.1 - Enhanced floating point support</title><link>http://baptiste-wicht.com/posts/2012/03/eddic-0-9-1-enhanced-floating-point-support.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I just released the version &lt;strong&gt;0.9.1&lt;/strong&gt; of the &lt;strong&gt;EDDI&lt;/strong&gt; Compiler (eddic).&lt;/p&gt;
&lt;p&gt;This release is a minor one, there are no huge changes to the language nor in the compiler itself. But that version was necessary before the 1.0 version. &lt;/p&gt;
&lt;p&gt;The floating point support of the language have been enhanced with casts. You can now cast float values to int and vice-versa. The syntax is the same as in C:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
   &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
   &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
   &lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Another improvement is the support for integer suffixes for float: &lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
   &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;100f&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Finally, the optimizer has been adapted to support float as well. The optimization techniques are the same as the one for integers. &lt;/p&gt;
&lt;p&gt;Last but not least, the compiler can now pass some parameters in registers. In 32 bits platform, the first integer parameter is passed in a register and on 64 bits platform, the first two parameters are passed in registers. In both architectures, the first float parameter is passed in a SSE register. &lt;/p&gt;
&lt;h4&gt;Future work&lt;/h4&gt;

&lt;p&gt;The next version will be the &lt;strong&gt;1.0 version&lt;/strong&gt;. There will be several major changes with this new version. &lt;/p&gt;
&lt;p&gt;First, the optimization engine will be almost entirely rewritten. Global optimization will be added to the engine. &lt;/p&gt;
&lt;p&gt;There will also be some improvements in the intermediate representation. I will probably a second level of intermediate representation: a low-level Three Address Code representation. This new intermediate representation will be generated by an &lt;em&gt;IntelCompiler&lt;/em&gt; to handle stuff common to both 32 and 64bits code generator. This will also includes a pass for global register allocation. &lt;/p&gt;
&lt;p&gt;As these changes will not be simple to implement, this version can takes some time before being released. &lt;/p&gt;
&lt;h4&gt;Download&lt;/h4&gt;

&lt;p&gt;You can find the compiler sources on the Github repository: &lt;a title="eddic on GitHub" href="https://github.com/wichtounet/eddic"&gt;https://github.com/wichtounet/eddic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The exact version I refer to is the v0.9.1 available in the GitHub tags or directly as the release branch.&lt;/p&gt;&lt;/div&gt;</description><category>Assembly</category><category>C++</category><category>Compilers</category><category>EDDI</category><category>Intel</category><guid>http://baptiste-wicht.com/posts/2012/03/eddic-0-9-1-enhanced-floating-point-support.html</guid><pubDate>Fri, 23 Mar 2012 08:16:53 GMT</pubDate></item><item><title>Introduction to 64 Bit Intel Assembly Language Programming for Linux - Book Review</title><link>http://baptiste-wicht.com/posts/2012/03/introduction-64-bit-intel-assembly-language-programming-linux-book-review.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;The first book I read about Intel Assembly was lacking information about 64 bits programming. So I ordered and read &lt;strong&gt;Introduction to 64 Bit Intel Assembly Language Programming for Linux&lt;/strong&gt;, by Ray Seyfarth. &lt;/p&gt;
&lt;p&gt;This book covers a lot of subjects in assembly. It is adapted to people starting assembly, but it also contains advanced assembly programming techniques. I think that this book is adapted to a lot of people wanting to improve their skills in Intel Assembly. This book covers only &lt;strong&gt;64 bit Intel Assembly&lt;/strong&gt; in details. It does not cover old memory models, only the memory mode used now. &lt;/p&gt;
&lt;p&gt;This book uses yasm to assemble the programs. It uses gdb to debug the assembly programs. &lt;/p&gt;
&lt;p&gt;The first chapters are very general. They are covering numbers (octal, decimal and hexadecimal notions), computer memory and memory mapping mode. &lt;/p&gt;
&lt;p&gt;The first technical chapter covers Registers in details. It defines all the registers available in Intel Assembly. You will see how to move constants to registers. You will also learn how to move values between memory and registers. Then, the next chapter covers all the mathematical operations (negate, addition, subtraction, division and multiplication). It also covers the use of conditional move instructions. The next one is about bit manipulations (not, and, or and shift). It also covers bit testing and filling. &lt;/p&gt;
&lt;p&gt;After that, the chapter eight covers a very important subject: branching and looping. All the jumps are covered in details. You will see how to convert each control structure (if, for, while, do-while) of programming language to assembly. After that, the string instructions are also explained. Once you know how to create control structures, it's time to create your own functions. In that chapter, you will learn the stack and the function call conventions. The stack frames and the recursion are also covered. &lt;/p&gt;
&lt;p&gt;The arrays are covered in the next chapter. You will see how to allocate arrays on the stack or on the heap using malloc. The command line parameters are also covered (that was a very interesting part). &lt;/p&gt;
&lt;p&gt;Then, floating point math is covered. For that, the &lt;strong&gt;Streaming SIMD Extensions&lt;/strong&gt; (SSE) are used. All the math operations are covered. As is the way to transfer data between XMM registers and memory. The conversion and comparison instructions are also explained here. Some complete samples like dot product of 3D vectors help us understand the SSE instructions. &lt;/p&gt;
&lt;p&gt;The system calls are covered in details in chapter twelve. The C system library wrapper functions for system calls are also covered. After that, a whole chapter addresses structures. The allocation of structs is also addressed. Then, the way to use I/O streams from assembly is taught. &lt;/p&gt;
&lt;p&gt;A whole chapter is devoted to the implementation of data structures in Intel Assembly. The covered data structures are the linked lists, doubly linked lists, the hash tables and the binary trees. Each common operation on these data structures is implemented. &lt;/p&gt;
&lt;p&gt;After that, the last chapters are about optimization and performances. The chapter 16 covers &lt;strong&gt;High Performance Assembly Programming&lt;/strong&gt; in details. In that chapter, you will learn a set of optimization that can be applied to improve the performances of a given code. For example, you will see how to make efficient use of cache or how to make better performing loops. These optimization can also be applied to other programming languages. The following chapters are all covering a single problem and a way to optimize it the most using Intel Assembly. For each of these problems, the C version is compared to the assembly version. Three problems are presented: counting bits in an array of integers, the Sobel filter and computing the correlation of two variables given some sample values. &lt;/p&gt;
&lt;p&gt;To conclude, I found this book very book. It covers a lot of subjects in a very good manner. I liked a lot the performance techniques covered in the book. The deep coverage of SSE instructions was also very interesting.&lt;/p&gt;&lt;/div&gt;</description><category>Assembly</category><category>Books</category><category>Intel</category><guid>http://baptiste-wicht.com/posts/2012/03/introduction-64-bit-intel-assembly-language-programming-linux-book-review.html</guid><pubDate>Mon, 19 Mar 2012 08:41:54 GMT</pubDate></item><item><title>EDDIC 0.9 - Floating point support</title><link>http://baptiste-wicht.com/posts/2012/03/eddic-0-9-floating-point-support.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I just finished working on the &lt;strong&gt;0.9 version&lt;/strong&gt; of the &lt;strong&gt;EDDIC&lt;/strong&gt; Compiler.&lt;/p&gt;
&lt;p&gt;The language does now support &lt;strong&gt;floating point variables&lt;/strong&gt;. Here is an example of what can be done in EDDI now:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
   &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
   &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
   &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
   &lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
   &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;2.75&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
   &lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

   &lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.0888&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.00222&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;

   &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
   &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;21.999&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;For now, there is no interoperability between integers and floating, so you can't add an integer to a floating point or cast a floating point to an integer. Those features will be added in the 0.9.1 version. The floating point support has been implemented using the Streaming SIMD Extension (SSE) of Intel processors. This won't work on processor that doesn't include support for SSE.&lt;/p&gt;
&lt;p&gt;Another big improvement is that the position of the tokens in the source file are now collected through the parser. When an error or a warning arises during the compilation, the precise position of the error or the warning is printed to the console.&lt;/p&gt;
&lt;p&gt;New options are available for eddic:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;--ast : Print the Abstract Syntax Tree representation of the source&lt;/li&gt;
    &lt;li&gt;--tac : Print the Three Address Code representation of the source&lt;/li&gt;
    &lt;li&gt;--ast-only : Only print the Abstract Syntax Tree representation of the source (do not continue compilation after printing)&lt;/li&gt;
    &lt;li&gt;--tac-only : Only print the Three Address Code representation of the source (do not continue compilation after printing)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And, finally, some improvements have been made to the sources of the project.&lt;/p&gt;
&lt;h4&gt;Download&lt;/h4&gt;

&lt;p&gt;You can find the compiler sources on the Github repository: &lt;a title="eddic on Github" href="https://github.com/wichtounet/eddic"&gt;https://github.com/wichtounet/eddic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The exact version I refer to is the v0.9 available in the github tags or directly as the release branch.&lt;/p&gt;&lt;/div&gt;</description><category>Assembly</category><category>Compilers</category><category>EDDI</category><category>Intel</category><guid>http://baptiste-wicht.com/posts/2012/03/eddic-0-9-floating-point-support.html</guid><pubDate>Wed, 07 Mar 2012 10:47:38 GMT</pubDate></item><item><title>Assembly Language Step By Step, Programming with Linux - Book Review</title><link>http://baptiste-wicht.com/posts/2012/02/assembly-language-step-by-step-book-review.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;To improve my skills in Intel Assembly, I ordered and read &lt;strong&gt;Assembly Language Step by Step&lt;/strong&gt;, Programming with Linux, by Jeff Duntemann. Just for the record, I read it on my Amazon Kindle. &lt;/p&gt;
&lt;p&gt;This book is really made for &lt;strong&gt;very&lt;/strong&gt; beginners. The author uses a lot of metaphor to explain some concepts, comparing assembly to a game he explains in several pages... I didn't liked the writing style of this book. In my opinion, the author uses way too much metaphor and some things takes too many pages to be explained. Another problem of this book is the examples, there are covering tens of pages each. It is a good thing to have complete examples in a book, but having examples of more than 100 lines of code (not counting the comments) in a book is not really convenient (again, only in my opinion). &lt;/p&gt;
&lt;p&gt;Another lack of this book is that it covers only 32 bit programming. For a book written in 2009, it is quite limited. And finally, I found it bad to not cover floating point. I think that this is an important subject. &lt;/p&gt;
&lt;p&gt;Even if I'm not a fan of this book, most of the content is still interesting and you can learn the basis of assembler with it if you're patient with the writing style, the metaphors and the long examples. &lt;/p&gt;
&lt;p&gt;If you are a real beginner in assembly and in programming in general, this book can still be valuable for you. &lt;/p&gt;
&lt;p&gt;The first chapters are covering computer programming, processors, arithmetic in different bases and memory locations. Then, the following chapters are covering the tools (assembler, linker and visual tools for editing and debugging). After that, we are jumping in the heart of the subject by learning arithmetic computations, system calls and stack control. The bits instructions are covered in details in a whole chapter. Then, you will be introduced to the writing of functions and how to use string instructions to simplify your programs. The last (and very big) chapter is about using the functions of the C library to performs work like I/O operations, time calculations, print formatted text and generate random numbers. For this last I would have preferred to learn how to do all that operations using only assembly, but it is important to know how to call C functions. &lt;/p&gt;
&lt;p&gt;To conclude, I will advice this book only to people who learn assembly as their first programming language. For the others, there is a high risk of be deceived. &lt;/p&gt;
&lt;p&gt;Note that, if you want to follow the examples of this book, you'll certainly need the Insight Debugger. You can install this debugger by following the procedure described &lt;a href="http://www.baptiste-wicht.com/2012/01/install-insight-debugger-linux-mint-ubuntu/" title="Install the Insight Debugger on Linux Mint (works for Ubuntu too)"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>Assembly</category><category>Intel</category><category>Linux</category><guid>http://baptiste-wicht.com/posts/2012/02/assembly-language-step-by-step-book-review.html</guid><pubDate>Fri, 17 Feb 2012 08:21:57 GMT</pubDate></item><item><title>EDDIC 0.8 : 64bit generation</title><link>http://baptiste-wicht.com/posts/2012/02/eddic-0-8-64bit-generation.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I just released the version 0.8.&lt;/p&gt;
&lt;p&gt;The main change of this version is the addition of a &lt;strong&gt;64bit generation&lt;/strong&gt;. If you compiles eddic in 64bit, the default output of the compiler will be 64 bit, otherwise it will be 32 bit. You can also select the output by setting command line switch (-32 and -64).&lt;/p&gt;
&lt;p&gt;The biggest change at the side of the language is the support of command line arguments. If the main function is declared as main(string[] args), the args passed from the command line will be accessible.&lt;/p&gt;
&lt;p&gt;I've also added two operators to the language : size() and length(). These operators allows the programmer to get the size of an array, respectively the length of a string. If the information is present at compile-time, the operator is replaced by the constant otherwise it is equivalent to a single memory access.&lt;/p&gt;
&lt;p&gt;I've also made some improvements to the generated x86 code. For example, I'm using string instructions to simplify the generated code and lea and shl to perform fast multiplications. I also changed the syntax used in the generated assembly replacing AT&amp;amp;T syntax by the Intel syntax.&lt;/p&gt;
&lt;p&gt;I've added a new optimization technique, copy propagation. This technique keeps track of the assignment of variables to a variables to simplify the generated three-address-code.&lt;/p&gt;
&lt;h4&gt;Download&lt;/h4&gt;

&lt;p&gt;You can find the compiler sources on the Github repository : &lt;a title="eddic on Github" href="https://github.com/wichtounet/eddic"&gt;https://github.com/wichtounet/eddic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The exact version I refer to is the v0.8 available in the github tags or directly as the release branch.&lt;/p&gt;&lt;/div&gt;</description><category>Assembly</category><category>EDDI</category><category>Intel</category><guid>http://baptiste-wicht.com/posts/2012/02/eddic-0-8-64bit-generation.html</guid><pubDate>Thu, 16 Feb 2012 12:44:32 GMT</pubDate></item><item><title>Dynamic memory allocation in Intel Assembly on Linux</title><link>http://baptiste-wicht.com/posts/2011/11/dynamic-memory-allocation-intel-assembly-linux.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;For the version 0.6.0 of the EDDI Compiler, I have written a simple dynamic memory allocation function in assembly. I did that to avoid using malloc in my assembly code. As this is not an easy subject, this article will explain the main parts of writing this function.&lt;/p&gt;
&lt;p&gt;As the EDDI Compiler creates program for Linux platform, this article will focus on writing a little memory allocator for Linux in Intel Assembly.&lt;/p&gt;
&lt;p&gt;In this article I will follow the &lt;em&gt;AT&amp;amp;T notation&lt;/em&gt;.&lt;/p&gt;
&lt;h4&gt;Specifications&lt;/h4&gt;

&lt;p&gt;The function works like malloc but is simpler. The specifications are the following ones:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;We call the function with one argument: the dynamic memory size we need&lt;/li&gt;
    &lt;li&gt;The function returns the start address of the allocated memory in the &lt;strong&gt;%eax&lt;/strong&gt; register&lt;/li&gt;
    &lt;li&gt;There is no need to deallocate the allocated memory&lt;/li&gt;
    &lt;li&gt;The size that we ask will generally small and always less than 16384 octets&lt;/li&gt;
    &lt;li&gt;Having some gaps in the memory is not a problem for now&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So as you can see there are several limitations to this memory allocator. These limitations are the one I had for EDDI, so I'll follow them in this article.&lt;/p&gt;
&lt;h4&gt;Dynamic memory allocation&lt;/h4&gt;

&lt;p&gt;In Linux, there are two ways for performing dynamic memory allocation:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;brk&lt;/strong&gt;: Increment the size of the data segment after the end of the program. This memory is directly after the program and is always contiguous. It's the easiest way for allocating memory. This technique is not perfect for large blocks of data.&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;mmap&lt;/strong&gt;: Creates a new memory mapping in the virtual address space. The kernel gives you memory in virtually every place of the memory.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In our case, as we need only small blocks, we will use &lt;strong&gt;brk&lt;/strong&gt; to dynamically allocate memory.&lt;/p&gt;
&lt;p&gt;We can call these procedures using system calls. In assembly, you can use system calls with interruptions (0x80).&lt;/p&gt;
&lt;h4&gt;Implementation&lt;/h4&gt;

&lt;p&gt;We need two variables for this function. One to keep track of the remaining size and another one to keep track of the current address of the allocated memory.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="na"&gt;.data&lt;/span&gt;
&lt;span class="na"&gt;.size&lt;/span&gt; &lt;span class="no"&gt;VIeddi_remaining&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;

&lt;span class="nl"&gt;VIeddi_remaining:&lt;/span&gt;
&lt;span class="na"&gt;.long&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="na"&gt;.size&lt;/span&gt; &lt;span class="no"&gt;VIeddi_current&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;

&lt;span class="nl"&gt;VIeddi_current:&lt;/span&gt;
&lt;span class="na"&gt;.long&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Both variables are initialized to 0.&lt;/p&gt;
&lt;p&gt;And here is the function I've developed :&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;eddi_alloc:&lt;/span&gt;
&lt;span class="nf"&gt;pushl&lt;/span&gt; &lt;span class="nv"&gt;%ebp&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%esp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebp&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;%ebp&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;VIeddi_remaining&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;cmpl&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;
&lt;span class="nf"&gt;jle&lt;/span&gt; &lt;span class="no"&gt;alloc_normal&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;xorl&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;int&lt;/span&gt;  &lt;span class="no"&gt;$0x80&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%esi&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;addl&lt;/span&gt; &lt;span class="no"&gt;$16384&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;int&lt;/span&gt;  &lt;span class="no"&gt;$0x80&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%esi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$16384&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="no"&gt;VIeddi_remaining&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%esi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="no"&gt;VIeddi_current&lt;/span&gt;

&lt;span class="nl"&gt;alloc_normal:&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;VIeddi_current&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;VIeddi_current&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;addl&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="no"&gt;VIeddi_current&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;VIeddi_remaining&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;subl&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="no"&gt;VIeddi_remaining&lt;/span&gt;
&lt;span class="nf"&gt;leave&lt;/span&gt;
&lt;span class="nf"&gt;ret&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;I will describe now each part of the alloc function.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;%ebp&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;VIeddi_remaining&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;cmpl&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;
&lt;span class="nf"&gt;jle&lt;/span&gt; &lt;span class="no"&gt;alloc_normal&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;In this part we test if there is enough remaining size for the dynamic memory allocation request. It's equivalent to &lt;em&gt;if(remaining &amp;gt;= size)&lt;/em&gt;. If there is enough size, we jump to the normal allocation part :&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;alloc_normal:&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;VIeddi_current&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;VIeddi_current&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;addl&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="no"&gt;VIeddi_current&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;VIeddi_remaining&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;subl&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="no"&gt;VIeddi_remaining&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;First, we move the current address of memory into the &lt;strong&gt;%eax&lt;/strong&gt; register for the return value. Then we add the size of the new allocated block to the current address. Finally we remove the size of the new allocated block from the remaining size. After that, we can leave the function.&lt;/p&gt;
&lt;p&gt;The most interesting part is what we do when we have to allocate more memory :&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;xorl&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;int&lt;/span&gt;  &lt;span class="no"&gt;$0x80&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%esi&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;addl&lt;/span&gt; &lt;span class="no"&gt;$16384&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;int&lt;/span&gt;  &lt;span class="no"&gt;$0x80&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$16384&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="no"&gt;VIeddi_remaining&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%esi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="no"&gt;VIeddi_current&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;We start by doing an interruption to execute a system call. The &lt;strong&gt;45&lt;/strong&gt; in the &lt;strong&gt;%eax&lt;/strong&gt; register indicates a &lt;strong&gt;sys_brk&lt;/strong&gt; call. The 0 in the &lt;strong&gt;%ebx&lt;/strong&gt; register, indicates that we want the current position of brk space. We save this current position into the &lt;strong&gt;%esi&lt;/strong&gt; register. Then we add 16384 bits (4K octets) to this address. We call again the &lt;strong&gt;sys_brk&lt;/strong&gt; routine to set the address of the brk space to the calculated address. This is the way to dynamically allocates 4K of memory. Finally, we add 4K to the remaining size in octets and we put the current address (before the add) as the current address.&lt;/p&gt;
&lt;h4&gt;Possible improvements&lt;/h4&gt;

&lt;p&gt;We should make some optimization if this function has to be invoked frequently. The first interruption (call to sys_brk) has only to be done once. The very first time we need to get the start address. Then, we can use the current address as the base address when we do the new allocation.&lt;/p&gt;
&lt;p&gt;Another improvement is to avoid having gaps between the used blocks. For that, we can avoid setting the current address directly to the newly allocated address but just add 4K to the remaining size. The blocks will overlap 2 allocated blocks.&lt;/p&gt;
&lt;p&gt;We could also check that the value returned by the &lt;strong&gt;sys_brk&lt;/strong&gt; is valid. On error, the procedure can return -1.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;In this post, we developed a basic dynamic memory allocation function in Intel assembly on the Linux platform. I hope that this information can helps some of you.&lt;/p&gt;
&lt;p&gt;Don't hesitate if you have a question or a comment on my implementation.&lt;/p&gt;&lt;/div&gt;</description><category>Assembly</category><category>EDDI</category><category>Intel</category><category>Linux</category><guid>http://baptiste-wicht.com/posts/2011/11/dynamic-memory-allocation-intel-assembly-linux.html</guid><pubDate>Tue, 29 Nov 2011 08:16:26 GMT</pubDate></item><item><title>How to print strings and integers in Intel Assembly on Linux ?</title><link>http://baptiste-wicht.com/posts/2011/11/print-strings-integers-intel-assembly.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;In this post, we'll learn how to print strings and integers to the console on Linux using Intel Assembly. In this post, I'll use the AT&amp;amp;T notation, because it's the notation used in EDDI. &lt;/p&gt;
&lt;p&gt;In EDDI, I have to print strings and numbers to the console, as this is not an easy exercise, I wanted to share my experience here. &lt;/p&gt;
&lt;p&gt;On Linux, the only way to print something on the console is to use a system call. For that, we have to use the 0x08 interrupt code. &lt;/p&gt;
&lt;h4&gt;Declare strings&lt;/h4&gt;

&lt;p&gt;First, we'll see how to declare strings in an Intel Assembly file. You can use the &lt;strong&gt;.string&lt;/strong&gt; instruction to achieve that : &lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;StringToPrint:&lt;/span&gt;
&lt;span class="na"&gt;.string&lt;/span&gt; &lt;span class="s"&gt;"Hello"&lt;/span&gt;
&lt;/pre&gt;


&lt;h4&gt;Print strings&lt;/h4&gt;

&lt;p&gt;Then, to print, we will call the &lt;em&gt;sys_write&lt;/em&gt; system call : &lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$StringToPrint&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%edx&lt;/span&gt;
&lt;span class="nf"&gt;int&lt;/span&gt; &lt;span class="no"&gt;$0x80&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The value in &lt;strong&gt;%eax&lt;/strong&gt; (4) indicates the system call we need (&lt;em&gt;sys_write&lt;/em&gt;). The 1 in &lt;strong&gt;%ebx&lt;/strong&gt; indicates that we want to write in the console. Finally the two last parameters indicates the string to print and the size of the string. In Intel assembly, the &lt;strong&gt;int&lt;/strong&gt; instruction launch an interrupt and the 0x80 in the interrupt table is set to the system call in the Linux Kernel. &lt;/p&gt;
&lt;p&gt;As you can see, this code does use 4 registers and does not save any of them. Ideally, you will save the registers before and restore them. It depends on when you use this routine. &lt;/p&gt;
&lt;h4&gt;Print integers&lt;/h4&gt;

&lt;p&gt;Writing an integer is a bit more complicated. If you have the integer in the string, there is no problem, but if you have only a long on your assembly, you'll have to convert the int into a string to print it. We will convert the integer char after char and use the stack as storage for our string. Then every char will be printed to the console using the same system as before. &lt;/p&gt;
&lt;p&gt;So let's say we have our number in the &lt;strong&gt;%eax&lt;/strong&gt; register : &lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$9234&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;So let's take a look at the code : &lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;xorl&lt;/span&gt; &lt;span class="nv"&gt;%esi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%esi&lt;/span&gt;

&lt;span class="nl"&gt;loop:&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%edx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;divl&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;addl&lt;/span&gt; &lt;span class="no"&gt;$48&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%edx&lt;/span&gt;
&lt;span class="nf"&gt;pushl&lt;/span&gt; &lt;span class="nv"&gt;%edx&lt;/span&gt;
&lt;span class="nf"&gt;incl&lt;/span&gt; &lt;span class="nv"&gt;%esi&lt;/span&gt;
&lt;span class="nf"&gt;cmpl&lt;/span&gt; &lt;span class="no"&gt;$0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;jz&lt;/span&gt;   &lt;span class="no"&gt;next&lt;/span&gt;
&lt;span class="nf"&gt;jmp&lt;/span&gt; &lt;span class="no"&gt;loop&lt;/span&gt;

&lt;span class="nl"&gt;next:&lt;/span&gt;
&lt;span class="nf"&gt;cmpl&lt;/span&gt; &lt;span class="no"&gt;$0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%esi&lt;/span&gt;
&lt;span class="nf"&gt;jz&lt;/span&gt;   &lt;span class="no"&gt;exit&lt;/span&gt;
&lt;span class="nf"&gt;decl&lt;/span&gt; &lt;span class="nv"&gt;%esi&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%esp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%edx&lt;/span&gt;
&lt;span class="nf"&gt;int&lt;/span&gt;  &lt;span class="no"&gt;$0x80&lt;/span&gt;
&lt;span class="nf"&gt;addl&lt;/span&gt; &lt;span class="no"&gt;$4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%esp&lt;/span&gt;
&lt;span class="nf"&gt;jmp&lt;/span&gt;  &lt;span class="no"&gt;next&lt;/span&gt;

&lt;span class="nl"&gt;exit:&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The first part of the code consists in dividing the value by 10 until we reach zero. The remainder of the division is pushed onto the stack. For example, for our number, after this part, we'll have 4-3-2-9 on the stack. The order is reversed, which is logic because we stack the remainders from the right. During this phase, we count the number of elements using the &lt;strong&gt;%esi&lt;/strong&gt; register. &lt;/p&gt;
&lt;p&gt;Once this is done, we print each characters one by one starting with the last that has been pushed. Here we decrement the counter for each char and we use the &lt;strong&gt;sys_write&lt;/strong&gt; call with &lt;strong&gt;%esp&lt;/strong&gt; as the address of the string of one character. After each character, we incremetn the &lt;strong&gt;%esp&lt;/strong&gt; to cancel the push that we used. &lt;/p&gt;
&lt;p&gt;We have to do this in two phases in order to get the characters in the good order and not in reverse order. &lt;/p&gt;
&lt;h4&gt;Handle negative numbers&lt;/h4&gt;

&lt;p&gt;As you may have noticed, we do not manage negative numbers in our code. They will be printed, but it will be positive number. Indeed, in Intel Assembly (and in processors in general), negative numbers are handled with two's complement. Handling negative numbers in our code is not a big deal. We can add this code at the beginning : &lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;cmpl&lt;/span&gt; &lt;span class="no"&gt;$0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;jge&lt;/span&gt; &lt;span class="no"&gt;loop&lt;/span&gt;
&lt;span class="nf"&gt;neg&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;pushl&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="c"&gt;; Print "-" &lt;/span&gt;
&lt;span class="nf"&gt;popl&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;First of all, we check if the number is smaller than 0, if it's not the case, we directly jump to the code we used before. If it's smaller, we negate the number and print a - before printing the real number. We have to save the &lt;strong&gt;%eax&lt;/strong&gt; register before printing the - character because &lt;strong&gt;%eax&lt;/strong&gt; is used for printing. &lt;/p&gt;
&lt;p&gt;You'll now have a complete procedure to print an integer on the console in assembly. &lt;/p&gt;
&lt;p&gt;I hope that this could be of some help for somebody.&lt;/p&gt;&lt;/div&gt;</description><category>Assembly</category><category>EDDI</category><category>Intel</category><category>Linux</category><guid>http://baptiste-wicht.com/posts/2011/11/print-strings-integers-intel-assembly.html</guid><pubDate>Wed, 23 Nov 2011 08:11:59 GMT</pubDate></item><item><title>EDDI 0.4 : Native compilation and swap operator</title><link>http://baptiste-wicht.com/posts/2011/07/eddi-0-4-native-compilation-swap.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;The version 0.4 of EDDI is released. &lt;/p&gt;
&lt;p&gt;There is only one new feature, the swap operator () to swap two variables together, but the biggest news is that now EDDI is not anymore an interpreted language, but is a compiled language. &lt;/p&gt;
&lt;p&gt;In fact, I rewritten the compiler in order to output Linux assembly code. For now the code is only 32 bits, but I plan to support 64 as well. I made that change in order to not having to write a virtual machine and in order to learn assembly as well. The current outputted assembly code is not really optimized and there will certainly be a lot of changes. Indeed, in order to simplify the switch to native compiler, I continued using stack operations, so that the numeric computations have a lot have a lot of stack operations in it. Moreover, I'm far from being a professional in assembly, so that, they can beginner's errors in the generated code. &lt;/p&gt;
&lt;p&gt;I use as to compile the assembly and then gcc to link. I will try to not depend on gcc, but it seems to be difficult if I want to use malloc (used for the string concatenation). &lt;/p&gt;
&lt;p&gt;You can download the sources and find some information on the GitHub repository : https://github.com/wichtounet/eddic/ (check the tag v0.4 if you want the exact version I refer in this post). &lt;/p&gt;
&lt;p&gt;Do not hesitate to send me your comments about the C++ code, the design or the outputted assembly. &lt;/p&gt;
&lt;p&gt;The first version will see loops integrated, certainly some assembly optimizations and some code refactorings I planned.&lt;/p&gt;&lt;/div&gt;</description><category>Assembly</category><category>C++</category><category>EDDI</category><category>Intel</category><category>Releases</category><guid>http://baptiste-wicht.com/posts/2011/07/eddi-0-4-native-compilation-swap.html</guid><pubDate>Wed, 20 Jul 2011 07:27:13 GMT</pubDate></item></channel></rss>